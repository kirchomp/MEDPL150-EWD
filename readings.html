<!DOCTYPE html>

<html>

<head>

<title>Reading Reflections</title>

</head>

<body>

  <h1>Reading Reflections</h1>
  <h2>Susan Sontag's 'On photography'</h2>
  <p>It’s a bit wild to think that Susan Sontag wrote what she did about photography and image making in relation to Plato’s Cave in 1977, when it seems so especially pertinent to contemporary society today. In the first chapter of her book, On Photography, Sontag explains that similar to the people trapped in the cave, people in our modern society have become enthralled or mesmerized with photographic images, and in turn, mistake them for ‘the truth’ or for reality. Sontag explains that there’s an innate power that a camera and/or photographic images have over a viewer, and therefore over society. They shape the viewer’s perception of what reality is, what the world is, and also what sights, objects, and / or events are considered ‘photo-worthy’. When I reflect on the ways in which I make images, and the reasons why I enjoy it so much, there’s definitely parts of what Sontag is saying that ring true for me. One of my biggest motivators for photographing things is for memory’s sake. I want to remember exactly what something looked like, or to capture a precise moment so that I can look back on it and remember the EXACT emotions I had at that specific moment. The experiences I want to photograph and therefore remember can sometimes be quite simple, even maybe boring for others to look at, but other times it’s my grandest adventures and most exciting days. Sontag touches on this same idea by discussing tourism and its relationship to the camera / photographs. She explains that traveling, in a way, has become ‘a strategy for accumulating photographs’ and that people like to put a camera in between themselves and the actual world, as a feeling of comfort. I relate to this all-too-well. But another significant reason why I like to make images is for their selective nature; for artistic purposes. Choosing how to frame a shot, what to include in the foreground / background, the emotion I hope to elicit from the person who sees it, are all part of a sort of manipulation of the viewer and how they see reality. By choosing how to present the world, I in turn influence other people’s perception of it. This comes back around to what Sontag was saying about the innate power of images. The world can be perceived in such different, polarizing ways, depending on who the viewer is, and to shape another person’s view of reality in accordance with your own via images, is an assertion of power over them. According to Sontag, there’s also a power specific to photographing people. By photographing someone, their existence is captured and placed into an object that can be literally or symbolically owned by somebody else. This reductionary practice comes with a certain power-struggle between the subject and the artist (or image-maker) but now seems commonplace in society. In my opinion, the best photos don’t have a strong sense of manipulation or don’t ask the viewer to look at something in a specific planned way, but invite them to reflect on how they’d LIKE to see it, how they’d LIKE to interpret a sliver of this here reality.
</p>

  <h2>Nesrine Malik's 'With ‘AI Slop’</h2>
  <p>Nesrine Malik writes about the phenomena and complexity of modern AI image-making with poignancy and relatability (I saw in real-time when Trump’s Instagram page posted the AI generated video ‘Trump-Gaza Number One’, and I thought it was absolutely insane that an government administration would allow that, and I was so glad to finally read something about how damaging content like that can be). I’d never considered that the politicization of AI content isn’t new and that it’s actually just a continuation of propaganda as a whole. Because it feels SO different and SO obviously ‘unreal’, it felt to me for the past year or so, that we are in totally uncharted territory (which we still are with AI as a whole) but it really is just a new form of propaganda. What’s new, as Malik points out, is how wide-spread and ‘normal’ this type of content is, and how with minimal human input, there are theoretically unlimited fictional scenarios that could be released to the public. 
Another huge point that Malik discusses, which I was not aware-of at all, is AI’s inherent bias towards conservative values and AGAINST minorities, on account of it being trained by pre-existing data, which tends to show a similar bias. This means that not only are these AI- generated-imagery confusing for certain people to ‘sort-out’ or differentiate as AI on the first hand, but then there also are being created illusions of ‘normality’, in topics such as race, religion, and sexual orientation, that don’t match the majority of modern’s society’s values of inclusion and condemnation of discrimination. This is truly scary, because obviously groups of people, such as elderly-people or young kids are more likely to be confused about whether something is AI or not to begin with, but now that AI-generated-content might be aligning with or corresponding to certain political values or beliefs, a certain bias will be, or already is being confirmed or instilled in these groups of susceptible internet viewers.
There are also the issues of our attention spans as visual consumers, monetary gain, and social media algorithms that Malik touches-on towards the end of the article relating to this idea of ‘AI-slop’. In my eyes, these phrases all circle around the general concept of incentive. There are people who post constantly on social media platforms and make money from those posts, and all the content is 100% AI nonsense. Why would those ‘creators’ choose to NOT make money from minimal human input? These creators are incentivized to keep making AI garbage because they’re profiting from it. The result for the viewer especially on sites like Facebook, as Malik and Max Read specifically mention, is an overflooded feed where the viewers’ minds are being overwhelmed, dulled, and then reshaped, based on a heavy-flow of content, and then social media accounts’ algorithms are trained to give the viewer more of this slop as long as they ate-up the previous slop with no issues. 
Where my brain goes instantly in the discussion of AI imagery, is the new generation of internet users. They will have to adopt a hyper-specific lens for interpreting media that previous generations haven’t needed for-the-most-part. AI will become integral (if it already isn’t) to image-making, but will it be decipherable as AI? It has to be, right? My opinion (or hope) is that people will in-the-end view our modern AI at this moment, as other image-making technology that we’ve seen invented in the last 30 years, like CGI graphics in films. But for some reason, deep down in my mind, that hope seems a tad farfetched. 
</p>

  <a href="index.html">Go back to homepage</a>


</body>

</html>
